{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Recommenders as DirMF baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we include required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T14:35:57.181570Z",
     "start_time": "2021-10-14T14:35:53.998670Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Flatten, Input, Dropout, Dense, Concatenate, Dot, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, ndcg_score, mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we configure the parameters of the experiments. Please, note that each cell contains the configuration for one dataset. Run only the cell of the dataset that you want to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T14:45:13.250433Z",
     "start_time": "2021-10-09T14:45:13.244353Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = 'ml1m'\n",
    "latent_dim = 5\n",
    "like_threshold = 4\n",
    "steps_per_epoch = None\n",
    "\n",
    "gmf_epochs = 10\n",
    "ncf_epochs = 10\n",
    "\n",
    "num_users = 6040\n",
    "num_items = 3706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T15:39:12.987422Z",
     "start_time": "2021-10-09T15:39:12.980987Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = 'filmtrust'\n",
    "latent_dim = 5\n",
    "like_threshold = 3\n",
    "steps_per_epoch = None\n",
    "\n",
    "gmf_epochs = 15\n",
    "ncf_epochs = 8\n",
    "\n",
    "num_users = 1508\n",
    "num_items = 2071"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T07:57:43.954351Z",
     "start_time": "2021-10-10T07:57:43.948359Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = 'myanimelist'\n",
    "latent_dim = 7\n",
    "like_threshold = 8\n",
    "steps_per_epoch = None\n",
    "\n",
    "gmf_epochs = 20\n",
    "ncf_epochs = 15\n",
    "\n",
    "num_users = 69600\n",
    "num_items = 9927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T14:36:01.277128Z",
     "start_time": "2021-10-14T14:36:01.271205Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = 'netflix'\n",
    "latent_dim = 6\n",
    "like_threshold = 4\n",
    "steps_per_epoch = 200000\n",
    "\n",
    "gmf_epochs = 5\n",
    "ncf_epochs = 4\n",
    "\n",
    "num_users = 480189\n",
    "num_items = 17770"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T14:36:29.412260Z",
     "start_time": "2021-10-14T14:36:03.702075Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/' + dataset + '/training-ratings.csv', delimiter = ',')\n",
    "df_test = pd.read_csv('../data/' + dataset + '/test-ratings.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset split into train and test partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T14:36:29.421066Z",
     "start_time": "2021-10-14T14:36:29.415412Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = [df_train['user'].to_numpy(), df_train['item'].to_numpy()]\n",
    "y_train = df_train['rating'].to_numpy()\n",
    "\n",
    "X_test = [df_test['user'].to_numpy(), df_test['item'].to_numpy()]\n",
    "y_test = df_test['rating'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural based Collaborative Filtering models definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T14:36:31.230755Z",
     "start_time": "2021-10-14T14:36:29.423615Z"
    }
   },
   "outputs": [],
   "source": [
    "user_input = Input(shape=[1])\n",
    "user_embedding = Embedding(num_users, latent_dim)(user_input)\n",
    "user_vec = Flatten()(user_embedding)\n",
    "\n",
    "item_input = Input(shape=[1])\n",
    "item_embedding = Embedding(num_items, latent_dim)(item_input)\n",
    "item_vec = Flatten()(item_embedding) \n",
    "        \n",
    "dot = Dot(axes=1)([item_vec, user_vec])\n",
    "    \n",
    "GMF = Model([user_input, item_input], dot)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model fitting using GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T18:06:42.256212Z",
     "start_time": "2021-10-14T14:36:31.233301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 6)         106620      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 6)         2881134     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6)            0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 6)            0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1)            0           flatten_1[0][0]                  \n",
      "                                                                 flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,987,754\n",
      "Trainable params: 2,987,754\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "200000/200000 [==============================] - 2542s 13ms/step - loss: 1.4751 - mae: 0.8920 - val_loss: 0.8915 - val_mae: 0.7369\n",
      "Epoch 2/5\n",
      "200000/200000 [==============================] - 2531s 13ms/step - loss: 0.8390 - mae: 0.7132 - val_loss: 0.8230 - val_mae: 0.7053\n",
      "Epoch 3/5\n",
      "200000/200000 [==============================] - 2512s 13ms/step - loss: 0.7886 - mae: 0.6893 - val_loss: 0.7945 - val_mae: 0.6918\n",
      "Epoch 4/5\n",
      "200000/200000 [==============================] - 2493s 12ms/step - loss: 0.7682 - mae: 0.6794 - val_loss: 0.7857 - val_mae: 0.6875\n",
      "Epoch 5/5\n",
      "199454/200000 [============================>.] - ETA: 6s - loss: 0.7583 - mae: 0.6745WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1000000 batches). You may need to use the repeat() function when building your dataset.\n",
      "199455/200000 [============================>.] - 2522s 13ms/step - loss: 0.7583 - mae: 0.6745 - val_loss: 0.7814 - val_mae: 0.6862\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    GMF.compile(optimizer='adam', metrics=['mae'], loss='mean_squared_error')\n",
    "    GMF.summary()\n",
    "\n",
    "    gmf_report = GMF.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=gmf_epochs, steps_per_epoch=steps_per_epoch, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T13:35:47.867812Z",
     "start_time": "2021-10-09T13:35:47.860418Z"
    }
   },
   "source": [
    "Model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T21:48:51.977414Z",
     "start_time": "2021-10-14T21:48:51.843640Z"
    }
   },
   "outputs": [],
   "source": [
    "item_input = Input(shape=[1], name='item-input')\n",
    "item_embedding = Embedding(num_items, latent_dim, name='item-embedding')(item_input)\n",
    "item_vec = Flatten(name='item-flatten')(item_embedding)\n",
    "\n",
    "user_input = Input(shape=[1], name='user-input')\n",
    "user_embedding = Embedding(num_users, latent_dim, name='user-embedding')(user_input)\n",
    "user_vec = Flatten(name='user-flatten')(user_embedding)\n",
    "\n",
    "concat = Concatenate(axis=1, name='item-user-concat')([item_vec, user_vec])\n",
    "fc_1 = Dense(70, name='fc-1', activation='relu')(concat)\n",
    "fc_1_dropout = Dropout(0.5, name='fc-1-dropout')(fc_1)\n",
    "fc_2 = Dense(30, name='fc-2', activation='relu')(fc_1_dropout)\n",
    "fc_2_dropout = Dropout(0.4, name='fc-2-dropout')(fc_2)\n",
    "fc_3 = Dense(1, name='fc-3', activation='relu')(fc_2_dropout)\n",
    "\n",
    "NCF = Model([user_input, item_input], fc_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model fitting using GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T00:40:04.970574Z",
     "start_time": "2021-10-14T21:48:53.838926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "item-input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user-input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item-embedding (Embedding)      (None, 1, 6)         106620      item-input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "user-embedding (Embedding)      (None, 1, 6)         2881134     user-input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item-flatten (Flatten)          (None, 6)            0           item-embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "user-flatten (Flatten)          (None, 6)            0           user-embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "item-user-concat (Concatenate)  (None, 12)           0           item-flatten[0][0]               \n",
      "                                                                 user-flatten[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc-1 (Dense)                    (None, 70)           910         item-user-concat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fc-1-dropout (Dropout)          (None, 70)           0           fc-1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc-2 (Dense)                    (None, 30)           2130        fc-1-dropout[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc-2-dropout (Dropout)          (None, 30)           0           fc-2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc-3 (Dense)                    (None, 1)            31          fc-2-dropout[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,990,825\n",
      "Trainable params: 2,990,825\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/4\n",
      "200000/200000 [==============================] - 2552s 13ms/step - loss: 0.8694 - mae: 0.7321 - val_loss: 0.8065 - val_mae: 0.6987\n",
      "Epoch 2/4\n",
      "200000/200000 [==============================] - 2577s 13ms/step - loss: 0.8105 - mae: 0.7046 - val_loss: 0.7968 - val_mae: 0.6946\n",
      "Epoch 3/4\n",
      "200000/200000 [==============================] - 2572s 13ms/step - loss: 0.8004 - mae: 0.6992 - val_loss: 0.7920 - val_mae: 0.6929\n",
      "Epoch 4/4\n",
      "199560/200000 [============================>.] - ETA: 5s - loss: 0.7943 - mae: 0.6959WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 800000 batches). You may need to use the repeat() function when building your dataset.\n",
      "199564/200000 [============================>.] - 2560s 13ms/step - loss: 0.7943 - mae: 0.6959 - val_loss: 0.7861 - val_mae: 0.6883\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    NCF.compile(optimizer='adam', metrics=['mae'], loss='mean_squared_error')\n",
    "    NCF.summary()\n",
    "    \n",
    "    ncf_report = NCF.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=ncf_epochs, steps_per_epoch=steps_per_epoch, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T00:40:04.982747Z",
     "start_time": "2021-10-15T00:40:04.975586Z"
    }
   },
   "outputs": [],
   "source": [
    "methods = ['gmf', 'ncf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T00:40:05.057768Z",
     "start_time": "2021-10-15T00:40:04.986390Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = pd.DataFrame()\n",
    "\n",
    "preds['user'] = X_test[0]\n",
    "preds['item'] = X_test[1]\n",
    "\n",
    "preds['y_test'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store predictions of the baselines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T00:40:17.283182Z",
     "start_time": "2021-10-15T00:40:05.060921Z"
    }
   },
   "outputs": [],
   "source": [
    "preds['gmf'] = GMF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T00:40:32.785389Z",
     "start_time": "2021-10-15T00:40:17.286839Z"
    }
   },
   "outputs": [],
   "source": [
    "preds['ncf'] = NCF.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T00:40:32.814819Z",
     "start_time": "2021-10-15T00:40:32.787994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\n",
      "- deepmf : 0.6861803149776209\n",
      "- ncf : 0.6882784305068139\n"
     ]
    }
   ],
   "source": [
    "print('MAE:')\n",
    "for m in methods:\n",
    "    print('-', m, ':', mean_absolute_error(preds['y_test'], preds[m]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality of the recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T00:40:32.826365Z",
     "start_time": "2021-10-15T00:40:32.817261Z"
    }
   },
   "outputs": [],
   "source": [
    "def recommender_precision_recall(X, y_true, y_pred, N, threshold):\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    count = 0\n",
    "    \n",
    "    rec_true = np.array([1 if rating >= threshold else 0 for rating in y_true])\n",
    "    rec_pred = np.zeros(y_pred.size)\n",
    "    \n",
    "    for user_id in np.unique(X[:,0]):\n",
    "        indices = np.where(X[:,0] == user_id)[0]\n",
    "        \n",
    "        rec_true = np.array([1 if y_true[i] >= threshold else 0 for i in indices])\n",
    "\n",
    "        if (np.count_nonzero(rec_true) > 0): # ignore test users without relevant ratings\n",
    "        \n",
    "            user_pred = np.array([y_pred[i] for i in indices])\n",
    "            rec_pred = np.zeros(indices.size)\n",
    "\n",
    "            for pos in np.argsort(user_pred)[-N:]:\n",
    "                if user_pred[pos] >= threshold:\n",
    "                    rec_pred[pos] = 1\n",
    "            \n",
    "            precision += precision_score(rec_true, rec_pred, zero_division=0)\n",
    "            recall += recall_score(rec_true, rec_pred)\n",
    "            count += 1\n",
    "        \n",
    "    return precision/count, recall/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T00:42:48.190515Z",
     "start_time": "2021-10-15T00:40:32.829488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- deepmf : \n",
      "\t precision:  0.600562101316028 \n",
      "\t recall:  0.29922371652744606\n",
      "- ncf : \n",
      "\t precision:  0.6401984761614494 \n",
      "\t recall:  0.3079389919867263\n"
     ]
    }
   ],
   "source": [
    "n = 10;\n",
    "\n",
    "for m in methods:\n",
    "    ids = preds[['user', 'item']].to_numpy()\n",
    "    y_true = preds['y_test'].to_numpy()\n",
    "    y_pred = preds[m].to_numpy()\n",
    "    precision, recall = recommender_precision_recall(ids, y_true, y_pred, n, like_threshold)\n",
    "    \n",
    "    print('-', m, ':', '\\n\\t', 'precision: ', precision, '\\n\\t', 'recall: ', recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
